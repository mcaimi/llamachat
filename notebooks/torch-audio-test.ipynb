{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191afd65-45f4-4db3-942d-6eaf2e301a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U pip\n",
    "%pip install -q numpy torchcodec torchaudio ffmpeg matplotlib\n",
    "%pip list |awk '/numpy|torch|ffmpeg|matplotlib/ {print $1,$2}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bc756f-0f2e-4b5b-99c7-78d093db0872",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import torchaudio as ta\n",
    "    import torchaudio.transforms as T\n",
    "    from torch import Tensor, arange\n",
    "    from torchcodec.decoders import AudioDecoder\n",
    "    from torchcodec.encoders import AudioEncoder\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    from pprint import pprint\n",
    "except ImportError as e:\n",
    "    print(f\"Import error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0715367-020f-447d-8503-66cb26017bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants and configurations\n",
    "AUDIO_FILE = \"1.MP3\"\n",
    "TARGET_SAMPLING_RATE = 16_000\n",
    "TARGET_NUM_CHANNEL = 1\n",
    "TARGET_FORMAT=\"mp3\"\n",
    "FREQUENCY_BINS = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d956f322-bf21-498e-bce0-2763be870382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load audio file\n",
    "audioClip = AudioDecoder(AUDIO_FILE)\n",
    "\n",
    "# explore results\n",
    "print(f\"Returned Type: {type(audioClip)}. Metadata: {type(audioClip.metadata)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6f6b44-e785-4e4f-9c20-b0ef85eb49b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print loaded file metadata\n",
    "pprint(audioClip.metadata)\n",
    "pprint(audioClip.get_all_samples().data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9781890-3858-4a46-bd60-a02d97a53a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample a clip\n",
    "def resample(audioClip: AudioDecoder, target_sample_rate: int = 16_000, target_num_channels: int = 1, target_format: str = \"mp3\") -> AudioDecoder:\n",
    "    # resample audio to desired format\n",
    "    samples, sample_rate = audioClip.get_all_samples().data, audioClip.metadata.sample_rate\n",
    "    encoder = AudioEncoder(samples, sample_rate=sample_rate)\n",
    "\n",
    "    # resample\n",
    "    resampledData: t.Tensor = encoder.to_tensor(format=target_format, num_channels=target_num_channels, sample_rate=target_sample_rate)\n",
    "\n",
    "    # return new AudioDecoder\n",
    "    return AudioDecoder(resampledData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33303fb1-a91d-4636-9c48-20f1c4c57aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify resampling...\n",
    "resampledClip = resample(audioClip, target_sample_rate=TARGET_SAMPLING_RATE, target_num_channels=TARGET_NUM_CHANNEL, target_format=TARGET_FORMAT)\n",
    "\n",
    "# view\n",
    "pprint(resampledClip.metadata)\n",
    "pprint(type(resampledClip))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea3e53e-9681-4f06-a14e-f995d9583327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot functions\n",
    "def waveform(clip: AudioDecoder, title: str = \"Waveform Plot\"):\n",
    "    # sample rate & channels\n",
    "    sr = clip.metadata.sample_rate\n",
    "    channels = clip.metadata.num_channels\n",
    "\n",
    "    # get samples\n",
    "    samples = clip.get_all_samples().data\n",
    "    nc, ns = samples.shape\n",
    "\n",
    "    # check\n",
    "    if nc != channels:\n",
    "        print(f\"Mismatch: reported channels in metadata: {channels} differ from Tensor shape: {samples.shape}\")\n",
    "    \n",
    "    # time scale (num_samples/sample_rate)\n",
    "    time_scale = arange(0, ns) / sr\n",
    "    \n",
    "    fig, axis = plt.subplots(nc,1)\n",
    "    fig.tight_layout()\n",
    "    if nc == 1:\n",
    "        values = samples[0]\n",
    "        axis.set_xlim([0,time_scale[-1]])\n",
    "        axis.plot(time_scale, values)\n",
    "        axis.set_ylabel(\"Amplitude\")\n",
    "        axis.set_xlabel(\"Time (s)\")\n",
    "    else:\n",
    "        for i in range(nc):\n",
    "            values = samples[i]\n",
    "            axis[i].set_xlim([0,time_scale[-1]])\n",
    "            axis[i].plot(time_scale, values)\n",
    "            axis[i].set_ylabel(\"Amplitude\")\n",
    "            axis[i].set_xlabel(\"Time (s)\")\n",
    "\n",
    "    return (fig, axis)\n",
    "\n",
    "# calculate audio spectrum\n",
    "def spectrum(clip: AudioDecoder, num_fft_bins: int = FREQUENCY_BINS, title: str = \"Power Spectrum\"):\n",
    "    # get samples\n",
    "    samples = clip.get_all_samples().data\n",
    "    sample_rate = clip.metadata.sample_rate\n",
    "    channels = clip.metadata.num_channels\n",
    "\n",
    "    # spectrum calculator\n",
    "    s = T.Spectrogram(n_fft=num_fft_bins, power=2)\n",
    "\n",
    "    # plot\n",
    "    fig, axis = plt.subplots(channels, 1)\n",
    "    if channels == 1:\n",
    "        # calculate spectrum of audio samples (power over frequency)\n",
    "        mono_data = samples\n",
    "        spectrogram = s(mono_data)\n",
    "    \n",
    "        # convert signal values to dB \n",
    "        samples_dB = T.AmplitudeToDB().forward(spectrogram)\n",
    "\n",
    "        # plot the spectrogram\n",
    "        axis.set_ylabel(\"Freq Bins\")\n",
    "        axis.set_xlabel(\"Time\")\n",
    "        axis.imshow(samples_dB.squeeze(), origin=\"lower\", aspect=\"auto\", interpolation=\"nearest\")\n",
    "    else:\n",
    "        # calculate spectrogram of each channel\n",
    "        for i in range(channels):\n",
    "            spectrogram = s(samples[i])\n",
    "            # convert signal values to dB \n",
    "            samples_dB = T.AmplitudeToDB().forward(spectrogram)\n",
    "\n",
    "            # plot the spectrogram\n",
    "            axis[i].set_ylabel(\"Freq Bins\")\n",
    "            axis[i].set_xlabel(\"Time\")\n",
    "            axis[i].imshow(samples_dB.squeeze(), origin=\"lower\", aspect=\"auto\", interpolation=\"nearest\")\n",
    "\n",
    "    # return the spectrogram\n",
    "    return (fig, axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb002c45-8a51-46c4-8782-7e1cc0af8f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot waveforms - original\n",
    "fig_original, axis_original = waveform(audioClip)\n",
    "# resampled\n",
    "fig_resampled, axis_resampled = waveform(resampledClip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f2fb8c-2556-4137-8544-883a371eec75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Spectrum - original\n",
    "spectrum_original, spectrum_axis_original = spectrum(audioClip, num_fft_bins=1024)\n",
    "\n",
    "# resampled audio\n",
    "spectrum_resampled, spectrum_axis_resampled = spectrum(resampledClip, num_fft_bins=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89eb7e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
